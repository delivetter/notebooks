{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29151be4",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd83ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ——— Librerías estándar ———\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "# ——— Análisis y manipulación de datos ———\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ——— Datos geoespaciales ———\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# ——— Grafos ———\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "\n",
    "# ——— Optimización y rutas ———\n",
    "from ortools.constraint_solver import pywrapcp, routing_enums_pb2\n",
    "\n",
    "# ——— Visualización geoespacial ———\n",
    "import folium\n",
    "from folium import FeatureGroup, Icon, GeoJson, LayerControl\n",
    "\n",
    "# ——— Visualización con gráficos ———\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# ——— Escalado y clustering ———\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# ——— Métricas de evaluación ———\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# ——— Progreso y paralelización ———\n",
    "from tqdm.auto import tqdm  # para barras de progreso\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de960a55",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7154fb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'barris.geojson' successfully loaded (63 records)\n",
      "✅ 'catastro.geojson' successfully loaded (36346 records)\n",
      "✅ 'puntosCID.geojson' successfully loaded (882 records)\n"
     ]
    }
   ],
   "source": [
    "def load_data(nombre_archivo, directorio_base='../../data/input'):\n",
    "    \"\"\"\n",
    "    Carga un archivo GeoJSON específico y devuelve un GeoDataFrame.\n",
    "    \n",
    "    Args:\n",
    "        nombre_archivo (str): Nombre del archivo GeoJSON (ej. 'barris.geojson').\n",
    "        directorio_base (str): Ruta relativa al directorio donde se encuentra el archivo.\n",
    "                              Por defecto: '../../data/delivetter'.\n",
    "    \n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: GeoDataFrame con los datos del archivo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ruta = Path(directorio_base) / nombre_archivo\n",
    "        \n",
    "        if not ruta.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {ruta.absolute()}\")\n",
    "        \n",
    "        gdf = gpd.read_file(ruta)\n",
    "        print(f\"✅ '{nombre_archivo}' successfully loaded ({len(gdf)} records)\")\n",
    "        return gdf\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading '{nombre_archivo}': {str(e)}\")\n",
    "    \n",
    "barrios = load_data('barris.geojson')\n",
    "catastro = load_data('catastro.geojson')\n",
    "puntos_carga = load_data('puntosCID.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e42359",
   "metadata": {},
   "source": [
    "## General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a859d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(request, seed=33):\n",
    "    global barrio, G_drive, G_walk, shp_zone, shp_loading_points, shp_bajos\n",
    "\n",
    "    shp_neighbourhood = barrios[barrios[\"nombre\"].str.strip().str.upper() == request.strip().upper()]\n",
    "    if len(shp_neighbourhood) != 1:\n",
    "        shp_neighbourhood = barrios[barrios[\"nombre\"].str.upper().str.contains(request.strip().upper())]\n",
    "    while len(shp_neighbourhood) != 1:\n",
    "        request = input(\"Please, introduce a valid neighbourhood: \")\n",
    "        shp_neighbourhood = barrios[barrios[\"nombre\"].str.strip().str.upper() == request.strip().upper()]\n",
    "        if len(shp_neighbourhood) == 1:\n",
    "            break\n",
    "        shp_neighbourhood = barrios[barrios[\"nombre\"].str.upper().str.contains(request.strip().upper())]\n",
    "\n",
    "    barrio = shp_neighbourhood[\"nombre\"].values[0]\n",
    "    shp_zone = shp_neighbourhood.geometry.values[0]\n",
    "    shp_loading_points = puntos_carga[puntos_carga.intersects(shp_zone)]\n",
    "    shp_bajos = catastro[catastro.intersects(shp_zone)]\n",
    "\n",
    "    G = ox.graph_from_polygon(\n",
    "        shp_zone,\n",
    "        network_type=\"all_public\",\n",
    "        simplify=False,\n",
    "        retain_all=False,\n",
    "        truncate_by_edge=True\n",
    "    )\n",
    "\n",
    "    not_highway = ['elevator', 'busway', 'corridor', 'unclassified', 'services', 'cycleway', 'steps', 'service']\n",
    "    allowed_vehicle = ['motorway', 'residential', 'secondary', 'living_street', 'primary_link', 'primary', 'tertiary', 'trunk', 'service', 'tertiary_link', 'trunk_link', 'secondary_link', 'motorway_link', 'road']\n",
    "    allowed_pedestrian = ['pedestrian', 'footway', 'path', 'track', 'bridleway', 'living_street', 'residential']\n",
    "\n",
    "    edges_to_remove = [(u, v, k) for u, v, k, data in G.edges(keys=True, data=True)\n",
    "                       if data.get('highway') in not_highway or data.get('access') in ['private', 'no', 'customers']]\n",
    "    G.remove_edges_from(edges_to_remove)\n",
    "\n",
    "    G_vehicle = G.copy()\n",
    "    G_pedestrian = G.copy()\n",
    "\n",
    "    edges_to_remove_vehicle = [(u, v, k) for u, v, k, data in G_vehicle.edges(keys=True, data=True)\n",
    "                                if data.get('highway') not in allowed_vehicle]\n",
    "    G_vehicle.remove_edges_from(edges_to_remove_vehicle)\n",
    "\n",
    "    edges_to_remove_pedestrian = [(u, v, k) for u, v, k, data in G_pedestrian.edges(keys=True, data=True)\n",
    "                                  if data.get('highway') not in allowed_pedestrian]\n",
    "    G_pedestrian.remove_edges_from(edges_to_remove_pedestrian)\n",
    "\n",
    "    for graph in [G_vehicle, G_pedestrian]:\n",
    "        nodes_to_remove = [node for node in graph.nodes if graph.degree(node) == 0]\n",
    "        graph.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    G_drive = G_vehicle.subgraph(max(nx.weakly_connected_components(G_vehicle), key=len)).copy()\n",
    "    G_walk = G_pedestrian.subgraph(max(nx.weakly_connected_components(G_pedestrian), key=len)).copy()\n",
    "\n",
    "    VELOCIDAD_PEATON=5\n",
    "    VELOCIDAD_VEHICULO=35\n",
    "    VELOCIDAD_CONEXION=10\n",
    "\n",
    "    \"\"\"\n",
    "    Construye el supergrafo uniendo G_drive y G_walk, añade nodos especiales\n",
    "    y calcula tiempos de viaje con velocidades muestreadas de distribuciones\n",
    "    normales. El parámetro `seed` hace que las muestras aleatorias sean reproducibles.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crea el RNG reproducible\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    # 1) Crear supergrafo vacío\n",
    "    G_super = nx.MultiDiGraph()\n",
    "    G_super.add_nodes_from(G_drive.nodes(data=True))\n",
    "    G_super.add_nodes_from(G_walk.nodes(data=True))\n",
    "\n",
    "    # 2) Función para fusionar aristas\n",
    "    def add_or_merge_edge(G, u, v, key, data, mode):\n",
    "        data = data.copy()\n",
    "        modos = data.get('mode', [])\n",
    "        if not isinstance(modos, list):\n",
    "            modos = [modos]\n",
    "        if mode not in modos:\n",
    "            modos.append(mode)\n",
    "        data['mode'] = modos\n",
    "\n",
    "        if G.has_edge(u, v):\n",
    "            for k_exist, existing in G[u][v].items():\n",
    "                if existing.get('geometry') == data.get('geometry'):\n",
    "                    exist_mod = existing.get('mode', [])\n",
    "                    if not isinstance(exist_mod, list):\n",
    "                        exist_mod = [exist_mod]\n",
    "                    for m in modos:\n",
    "                        if m not in exist_mod:\n",
    "                            exist_mod.append(m)\n",
    "                    existing['mode'] = exist_mod\n",
    "                    return\n",
    "        G.add_edge(u, v, key=key, **data)\n",
    "\n",
    "    # Añadir aristas de conducción\n",
    "    for u, v, k, data in G_drive.edges(keys=True, data=True):\n",
    "        add_or_merge_edge(G_super, u, v, k, data, 'drive')\n",
    "        if not data.get('oneway', True) or data.get('reversed', False):\n",
    "            add_or_merge_edge(G_super, v, u, k, data, 'drive')\n",
    "        elif not G_drive.has_edge(v, u):\n",
    "            fake_data = data.copy()\n",
    "            fake_data['fake'] = True\n",
    "            dist = fake_data.get('length', 100)\n",
    "            fake_data['length'] = dist * 5\n",
    "            add_or_merge_edge(G_super, v, u, k, fake_data, 'drive')\n",
    "\n",
    "    # Añadir aristas de paseo\n",
    "    for u, v, k, data in G_walk.edges(keys=True, data=True):\n",
    "        add_or_merge_edge(G_super, u, v, k, data, 'walk')\n",
    "        if not G_walk.has_edge(v, u):\n",
    "            add_or_merge_edge(G_super, v, u, k, data, 'walk')\n",
    "\n",
    "    # 3) Haversine helper\n",
    "    def haversine(coord1, coord2):\n",
    "        lon1, lat1, lon2, lat2 = map(math.radians, [*coord1, *coord2])\n",
    "        dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "        a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "        return 2 * math.asin(math.sqrt(a)) * 6371000\n",
    "\n",
    "    # 4) Función para añadir nodo especial\n",
    "    def add_special_node(G, geom, tipo, idx):\n",
    "        nid = f\"{tipo}_{idx}\"\n",
    "        lon, lat = geom.centroid.x, geom.centroid.y\n",
    "        G.add_node(nid, x=lon, y=lat, tipo=tipo)\n",
    "\n",
    "        conexiones = []\n",
    "        if tipo in ['carga', 'almacen']:\n",
    "            nd = ox.distance.nearest_nodes(G_drive, lon, lat)\n",
    "            conexiones.append((nd, 'drive',\n",
    "                                haversine((lon, lat),\n",
    "                                          (G_drive.nodes[nd]['x'], G_drive.nodes[nd]['y']))))\n",
    "            nw = ox.distance.nearest_nodes(G_walk, lon, lat)\n",
    "            conexiones.append((nw, 'walk',\n",
    "                                haversine((lon, lat),\n",
    "                                          (G_walk.nodes[nw]['x'], G_walk.nodes[nw]['y']))))\n",
    "        else:\n",
    "            nw = ox.distance.nearest_nodes(G_walk, lon, lat)\n",
    "            conexiones.append((nw, 'walk',\n",
    "                                haversine((lon, lat),\n",
    "                                          (G_walk.nodes[nw]['x'], G_walk.nodes[nw]['y']))))\n",
    "\n",
    "        for vec, modo, dist in conexiones:\n",
    "            G.add_edge(nid, vec, mode=['connection', modo], length=dist)\n",
    "            G.add_edge(vec, nid, mode=['connection', modo], length=dist)\n",
    "\n",
    "        return nid\n",
    "\n",
    "    nodos_carga = [\n",
    "        add_special_node(G_super, row.geometry, 'carga', i)\n",
    "        for i, row in shp_loading_points.iterrows()\n",
    "    ]\n",
    "    nodos_comercios = [\n",
    "        add_special_node(G_super, row.geometry, 'comercio', i)\n",
    "        for i, row in shp_bajos[shp_bajos['Comercio']].iterrows()\n",
    "    ]\n",
    "    nodos_almacenes = [\n",
    "        add_special_node(G_super, row.geometry, 'almacen', i)\n",
    "        for i, row in shp_bajos[shp_bajos['Almacen']].iterrows()\n",
    "    ]\n",
    "\n",
    "    # 5) Añadir tiempos a aristas\n",
    "    def calcular_tiempos_en_aristas(G, v_w, v_v, v_c, rng):\n",
    "        def tpd(dist, vel):\n",
    "            return dist / (vel * 1000 / 60)\n",
    "\n",
    "        # Muestras con el RNG local\n",
    "        v_peat = rng.normal(v_w, 0.2 * v_w, 30)\n",
    "        v_conn = rng.normal(v_c, 0.2 * v_c, 30)\n",
    "        v_veh  = rng.normal(v_v, 0.2 * v_v, 30)\n",
    "\n",
    "        for u, v, k, data in G.edges(keys=True, data=True):\n",
    "            d = data.get('length', 100)\n",
    "            modos = data.get('mode', [])\n",
    "\n",
    "            if 'connection' in modos:\n",
    "                data['tiempo_walk']  = tpd(d, rng.choice(v_peat))\n",
    "                data['tiempo_drive'] = tpd(d, rng.choice(v_conn))\n",
    "                continue\n",
    "\n",
    "            if 'walk' in modos:\n",
    "                data['tiempo_walk'] = tpd(d, rng.choice(v_peat))\n",
    "\n",
    "            if 'drive' in modos:\n",
    "                vmax = data.get('maxspeed', rng.choice(v_veh))\n",
    "                if isinstance(vmax, str):\n",
    "                    vmax = int(''.join(filter(str.isdigit, vmax)) or 30)\n",
    "                vkh = max(vmax * 0.5, rng.normal(vmax * 0.8, vmax * 0.1))\n",
    "                data['tiempo_drive'] = tpd(d, vkh)\n",
    "\n",
    "            # Asegurar que existe la clave\n",
    "            data.setdefault('tiempo_walk', float('inf'))\n",
    "            data.setdefault('tiempo_drive', float('inf'))\n",
    "\n",
    "    calcular_tiempos_en_aristas(G_super,\n",
    "                                VELOCIDAD_PEATON,\n",
    "                                VELOCIDAD_VEHICULO,\n",
    "                                VELOCIDAD_CONEXION,\n",
    "                                rng)\n",
    "\n",
    "    print(f\"✅ Supergraph {barrio} created: {len(G_super.nodes)} nodes, {len(G_super.edges)} edges.\")\n",
    "    return G_super, nodos_carga, nodos_comercios, nodos_almacenes\n",
    "\n",
    "def calcular_tiempo_walk(G, origen, destino):\n",
    "    \"\"\"Ruta más rápida a pie entre origen y destino (minutos), usando el grafo G.\"\"\"\n",
    "    try:\n",
    "        camino = nx.shortest_path(G, origen, destino, weight='tiempo_walk')\n",
    "    except nx.NetworkXNoPath:\n",
    "        return float('inf'), None\n",
    "    tiempo = 0.0\n",
    "    for u, v in zip(camino[:-1], camino[1:]):\n",
    "        ed = G.get_edge_data(u, v)\n",
    "        t_min = min(e['tiempo_walk'] for e in ed.values())\n",
    "        tiempo += t_min\n",
    "    return tiempo, camino\n",
    "\n",
    "def calcular_tiempo_drive(G, origen, destino):\n",
    "    \"\"\"Ruta más rápida en vehículo entre origen y destino (minutos), usando el grafo G.\"\"\"\n",
    "    try:\n",
    "        camino = nx.shortest_path(G, origen, destino, weight='tiempo_drive')\n",
    "    except nx.NetworkXNoPath:\n",
    "        return float('inf'), []\n",
    "    tiempo = 0.0\n",
    "    for u, v in zip(camino[:-1], camino[1:]):\n",
    "        ed = G.get_edge_data(u, v)\n",
    "        tiempo += min(e.get('tiempo_drive', math.inf) for e in ed.values())\n",
    "    return tiempo, camino\n",
    "\n",
    "def generate_context(nodos_comercios,\n",
    "                     N_PAQUETES=100,\n",
    "                     PAQUETES_MIN=1,\n",
    "                     PAQUETES_MAX=5,\n",
    "                     CAPACIDAD_MAXIMA=8,\n",
    "                     FACTOR_AJUSTE=0.75,\n",
    "                     seed=None):\n",
    "    \"\"\"\n",
    "    Selecciona comercios aleatorios y reparte paquetes sobre ellos de forma eficiente,\n",
    "    eliminando del muestreo aquellos nodos que no puedan recibir la cantidad mínima de paquetes.\n",
    "\n",
    "    Args:\n",
    "      nodos_comercios (list): lista de IDs de nodo “comercio” en G_super (variable global).\n",
    "      N_PAQUETES      (int): total de paquetes a repartir.\n",
    "      PAQUETES_MIN    (int): mínimo paquetes por comercio.\n",
    "      PAQUETES_MAX    (int): máximo paquetes por comercio.\n",
    "      CAPACIDAD_MAXIMA(int): capacidad máxima que un nodo puede recibir.\n",
    "      FACTOR_AJUSTE   (float): factor para ajustar N_PAQUETES cuando se acerca al límite de capacidad.\n",
    "\n",
    "    Devuelve:\n",
    "      n_paq (int): número final de paquetes asignados.\n",
    "      GeoDataFrame con columnas ['node', 'paquetes', 'geometry'].\n",
    "      entrada (str): nodo de entrada para el repartidor.\n",
    "    \"\"\"\n",
    "\n",
    "    # Instanciamos un RNG local\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    \n",
    "    # Validación de parámetros\n",
    "    if (PAQUETES_MAX < PAQUETES_MIN or PAQUETES_MIN < 0 or \n",
    "        PAQUETES_MAX < 0 or CAPACIDAD_MAXIMA < 0 or \n",
    "        CAPACIDAD_MAXIMA < min(PAQUETES_MIN, PAQUETES_MAX)):\n",
    "        raise ValueError(\"Invalid values for constants. Check the input values.\")\n",
    "    \n",
    "    n_comercios = len(nodos_comercios)\n",
    "    max_paquetes = n_comercios * CAPACIDAD_MAXIMA\n",
    "    proporcion = N_PAQUETES / max_paquetes\n",
    "    \n",
    "    # Ajuste preliminar de N_PAQUETES si la proporción es alta\n",
    "    if proporcion >= FACTOR_AJUSTE:\n",
    "        N_PAQUETES = int(max_paquetes * FACTOR_AJUSTE)\n",
    "    \n",
    "    # Inicializar capacidades y lista de nodos disponibles\n",
    "    capacidades = {nodo: CAPACIDAD_MAXIMA for nodo in nodos_comercios}\n",
    "    available_nodes = nodos_comercios.copy()  # lista mutable de nodos disponibles\n",
    "\n",
    "    # Listas para almacenar asignaciones\n",
    "    seleccionados = []\n",
    "    paquetes_asignados_list = []\n",
    "    \n",
    "    paquetes_asignados = 0\n",
    "    n_paq = N_PAQUETES\n",
    "\n",
    "    # Bucle principal: mientras haya paquetes por asignar y nodos disponibles\n",
    "    while paquetes_asignados < N_PAQUETES and available_nodes:\n",
    "        restante = N_PAQUETES - paquetes_asignados\n",
    "        max_pos = min(PAQUETES_MAX, restante)\n",
    "        if max_pos < PAQUETES_MIN:\n",
    "            break\n",
    "\n",
    "        # Selección aleatoria eficiente: \n",
    "        idx = available_nodes.index(rng.choice(available_nodes))\n",
    "        nodo = available_nodes[idx]\n",
    "        cap_restante = capacidades[nodo]\n",
    "\n",
    "        # Si el nodo no tiene capacidad para PAQUETES_MIN, se elimina de la lista\n",
    "        if cap_restante < PAQUETES_MIN:\n",
    "            available_nodes[idx] = available_nodes[-1]\n",
    "            available_nodes.pop()\n",
    "            continue\n",
    "\n",
    "        # Determinar la cantidad de paquetes a asignar\n",
    "        paquetes_a_asignar = rng.randint(PAQUETES_MIN, min(max_pos, cap_restante)+1)\n",
    "        \n",
    "        # Registrar la asignación\n",
    "        seleccionados.append(nodo)\n",
    "        paquetes_asignados_list.append(paquetes_a_asignar)\n",
    "        \n",
    "        capacidades[nodo] -= paquetes_a_asignar\n",
    "        paquetes_asignados += paquetes_a_asignar\n",
    "\n",
    "        # Si tras la asignación la capacidad es insuficiente, se elimina el nodo de la lista\n",
    "        if capacidades[nodo] < PAQUETES_MIN:\n",
    "            available_nodes[idx] = available_nodes[-1]\n",
    "            available_nodes.pop()\n",
    "    \n",
    "    # Agrupar las asignaciones por nodo\n",
    "    asignacion_por_nodo = {}\n",
    "    for nodo, paquetes in zip(seleccionados, paquetes_asignados_list):\n",
    "        asignacion_por_nodo[nodo] = asignacion_por_nodo.get(nodo, 0) + paquetes\n",
    "\n",
    "    # Construir la lista de datos para el GeoDataFrame usando la variable global G_super para obtener coordenadas\n",
    "    data = []\n",
    "    for nodo, total in asignacion_por_nodo.items():\n",
    "        lon = G_super.nodes[nodo]['x']\n",
    "        lat = G_super.nodes[nodo]['y']\n",
    "        data.append({\n",
    "            'node': nodo,\n",
    "            'paquetes': total,\n",
    "            'geometry': Point(lon, lat)\n",
    "        })\n",
    "\n",
    "    # Elegir punto de entrada\n",
    "    thresh, thresh_max = 0.0001, 0.1\n",
    "    entrada = None\n",
    "    while entrada is None:\n",
    "        boundary = [n for n, d in G_super.nodes(data=True)\n",
    "                    if shp_zone.boundary.distance(Point(d['x'], d['y'])) < thresh and 'tipo' not in data ]\n",
    "        if len(boundary) < 5:\n",
    "            thresh = min(thresh * 3, thresh_max)\n",
    "            if thresh >= thresh_max:\n",
    "                raise RuntimeError(\"No hay nodos periféricos válidos.\")\n",
    "            continue\n",
    "\n",
    "        rng.shuffle(boundary)\n",
    "        for b in boundary: \n",
    "            random_cid = rng.choice(nodos_carga)\n",
    "            try:\n",
    "                t, _ = calcular_tiempo_drive(G_super, b, random_cid) # para asegura que esta en drive\n",
    "                if t < 1000:\n",
    "                    entrada = b\n",
    "                    break\n",
    "            except nx.NetworkXNoPath:\n",
    "               continue\n",
    "        thresh = min(thresh * 3, thresh_max)\n",
    "\n",
    "    return n_paq, gpd.GeoDataFrame(data, crs=\"EPSG:4326\"), entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686adeef",
   "metadata": {},
   "source": [
    "## M1 (VAN MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f094cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_M1(df_comercios, nodo_entrada, nodos_carga, CAPACIDAD_MAXIMA=8):\n",
    "    ########\n",
    "    # 1º\n",
    "    ########\n",
    "    def cid_assigment(df_comercios, nodos_carga, CAPACIDAD_MAXIMA = CAPACIDAD_MAXIMA, extra_penalty=0.1):\n",
    "        \"\"\"\n",
    "        Heurística Marginal Trips.\n",
    "\n",
    "        Args:\n",
    "        df_comercios     : GeoDataFrame con ['node','paquetes','geometry'].\n",
    "        nodos_carga      : lista de nodos CID.\n",
    "        CAPACIDAD_MAXIMA : capacidad máxima de carga del repartidor.\n",
    "        extra_penalty    : factor multiplicativo para penalizar viajes extra.\n",
    "\n",
    "        Devuelve:\n",
    "        assign_df : DataFrame con ['commerce_id','paquetes','assigned_cid',\n",
    "                                    'walk_time_min','delta_runs'].\n",
    "        loads_df  : GeoDataFrame con ['node','geometry','total_load','required_runs'].\n",
    "        \"\"\"\n",
    "        # Construir df_cid\n",
    "        df_cid = gpd.GeoDataFrame(\n",
    "            {'node': nodos_carga},\n",
    "            geometry=[Point(G_super.nodes[n]['x'], G_super.nodes[n]['y']) for n in nodos_carga],\n",
    "            crs=df_comercios.crs\n",
    "        )\n",
    "\n",
    "        # 1) Matriz de tiempos a pie\n",
    "        n, m = len(df_comercios), len(df_cid)\n",
    "        time_walk = np.zeros((n, m))\n",
    "        for i, ci in df_comercios.iterrows():\n",
    "            for j, sj in df_cid.iterrows():\n",
    "                t, _ = calcular_tiempo_walk(G_super, sj['node'], ci['node'])  \n",
    "                time_walk[i, j] = t\n",
    "\n",
    "        # 2) Asignación Marginal Trips\n",
    "        L = np.zeros(m, dtype=int)\n",
    "        assignments = []\n",
    "        for i, ci in df_comercios.iterrows():\n",
    "            best_cost, best_j = float('inf'), None\n",
    "            for j, sj in df_cid.iterrows():\n",
    "                runs_before = math.ceil(L[j] / CAPACIDAD_MAXIMA)\n",
    "                runs_after  = math.ceil((L[j] + ci['paquetes']) / CAPACIDAD_MAXIMA)\n",
    "                delta_runs  = runs_after - runs_before\n",
    "                cost = time_walk[i, j] + time_walk[i, j] * delta_runs * extra_penalty\n",
    "                if cost < best_cost:\n",
    "                    delta_f = delta_runs\n",
    "                    best_cost, best_j = cost, j\n",
    "\n",
    "            assignments.append({\n",
    "                'commerce_id':  ci['node'],\n",
    "                'paquetes':     ci['paquetes'],\n",
    "                'assigned_cid': df_cid.loc[best_j, 'node'],\n",
    "                'walk_time_min': time_walk[i, best_j],\n",
    "                'delta_runs':    delta_f\n",
    "            })\n",
    "            L[best_j] += ci['paquetes']\n",
    "\n",
    "        assign_df = pd.DataFrame(assignments)\n",
    "\n",
    "        # 3) Cargas y viajes requeridos\n",
    "        loads_df = gpd.GeoDataFrame({\n",
    "            'node':        df_cid['node'],\n",
    "            'geometry':    df_cid['geometry'],\n",
    "            'total_load':  L,\n",
    "            'required_runs': np.ceil(L / CAPACIDAD_MAXIMA).astype(int)\n",
    "        }, crs=df_cid.crs)\n",
    "\n",
    "        return assign_df, loads_df\n",
    "\n",
    "    \n",
    "    assign_df, loads_df = cid_assigment(df_comercios,\n",
    "                                        nodos_carga, \n",
    "                                        CAPACIDAD_MAXIMA=CAPACIDAD_MAXIMA,\n",
    "                                        extra_penalty=0.05\n",
    "                                    )\n",
    "\n",
    "    ########\n",
    "    # 2º\n",
    "    ########\n",
    "\n",
    "    def walk_routes(assign_df, loads_df, CAPACIDAD_MAXIMA=CAPACIDAD_MAXIMA):\n",
    "        \"\"\"\n",
    "        CVRP con OR-Tools, tiempos en segundos, manejo de 'inf'\n",
    "        y cómputo de distancia recorrida por ruta.\n",
    "\n",
    "        Args:\n",
    "        assign_df          : DataFrame con ['commerce_id','paquetes','assigned_cid'].\n",
    "        loads_df           : GeoDataFrame con ['node',...].\n",
    "        capacidad_maxima   : int, Q paquetes por ruta.\n",
    "\n",
    "        Returns:\n",
    "        routes_df : DataFrame ['cid','batch','sequence','time_min','distance_km','load'].\n",
    "        \"\"\"\n",
    "        all_routes = []\n",
    "        total_time_sec = 0\n",
    "        total_batches = 0\n",
    "        INF_SEC = 10**9\n",
    "\n",
    "        for _, row in loads_df.iterrows():\n",
    "            cid = row['node']\n",
    "            assigned = assign_df[assign_df['assigned_cid'] == cid]\n",
    "            if assigned.empty:\n",
    "                continue\n",
    "\n",
    "            # 1) nodos y demandas\n",
    "            locations = [cid] + assigned['commerce_id'].tolist()\n",
    "            demands   = [0]   + assigned['paquetes'].tolist()\n",
    "            N = len(locations)\n",
    "\n",
    "            # 2) matriz de tiempos (segundos)\n",
    "            time_matrix = [[0]*N for _ in range(N)]\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    if i == j: continue\n",
    "                    try:\n",
    "                        t_min, _ = calcular_tiempo_walk(G_super, locations[i], locations[j])  # Intentamos con G_super\n",
    "                    except Exception:\n",
    "                        t_min = INF_SEC\n",
    "                    time_matrix[i][j] = INF_SEC if not np.isfinite(t_min) else int(math.ceil(t_min*60))\n",
    "\n",
    "            # 3) número de rutas necesarias\n",
    "            total_demand = sum(demands)\n",
    "            R = math.ceil(total_demand / CAPACIDAD_MAXIMA)\n",
    "\n",
    "            # 4) configurar OR-Tools\n",
    "            manager = pywrapcp.RoutingIndexManager(N, R, 0)\n",
    "            routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "            def time_callback(f, t):\n",
    "                return time_matrix[manager.IndexToNode(f)][manager.IndexToNode(t)]\n",
    "            cb_t = routing.RegisterTransitCallback(time_callback)\n",
    "            routing.SetArcCostEvaluatorOfAllVehicles(cb_t)\n",
    "\n",
    "            def demand_callback(idx):\n",
    "                return demands[manager.IndexToNode(idx)]\n",
    "            cb_d = routing.RegisterUnaryTransitCallback(demand_callback)\n",
    "            routing.AddDimensionWithVehicleCapacity(cb_d, 0, [CAPACIDAD_MAXIMA+1]*R, True, \"Capacity\")\n",
    "\n",
    "            search_params = pywrapcp.DefaultRoutingSearchParameters()\n",
    "            search_params.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.SAVINGS\n",
    "            search_params.time_limit.seconds = 3\n",
    "\n",
    "            try:\n",
    "                sol = routing.SolveWithParameters(search_params)\n",
    "                if not sol:\n",
    "                    raise RuntimeError(f\"No solution CVRP for CID {cid}\")\n",
    "            except RuntimeError:\n",
    "                (f\"No solution CVRP for CID {cid}\")\n",
    "                continue\n",
    "            # 5) extraer rutas y calcular distancia\n",
    "            for v in range(R):\n",
    "                idx = routing.Start(v)\n",
    "                if routing.IsEnd(sol.Value(routing.NextVar(idx))):\n",
    "                    continue\n",
    "                seq_nodes = []\n",
    "                load = 0\n",
    "                time_sec = 0\n",
    "                dist_m = 0.0\n",
    "                # construir ruta\n",
    "                while not routing.IsEnd(idx):\n",
    "                    n = manager.IndexToNode(idx)\n",
    "                    seq_nodes.append(locations[n])\n",
    "                    load += demands[n]\n",
    "                    nxt = sol.Value(routing.NextVar(idx))\n",
    "                    time_sec += routing.GetArcCostForVehicle(idx, nxt, v)\n",
    "\n",
    "                    # distancia tramo a tramo\n",
    "                    a, b = locations[n], locations[manager.IndexToNode(nxt)]\n",
    "                    _, path = calcular_tiempo_walk(G_super, a, b)  # Usamos G_super para la distancia\n",
    "                    if path:\n",
    "                        for u, w in zip(path[:-1], path[1:]):\n",
    "                            ed = G_super.get_edge_data(u, w)\n",
    "                            dist_m += min(e.get('length', 0) for e in ed.values())\n",
    "\n",
    "                    idx = nxt\n",
    "\n",
    "                # retorno opcional al depósito\n",
    "                seq_nodes.append(cid)\n",
    "\n",
    "                all_routes.append({\n",
    "                    'cid':         cid,\n",
    "                    'travel_number':       v+1,\n",
    "                    'sequence':    seq_nodes,\n",
    "                    'time_min':    round(time_sec/60, 3),\n",
    "                    'distance_km': round(dist_m/1000, 3),\n",
    "                    'load':        load\n",
    "                })\n",
    "                total_time_sec += time_sec\n",
    "                total_batches += 1\n",
    "\n",
    "        routes_df = pd.DataFrame(all_routes)\n",
    "        return routes_df\n",
    "\n",
    "\n",
    "    routes_df = walk_routes(\n",
    "        assign_df,\n",
    "        loads_df, \n",
    "        CAPACIDAD_MAXIMA=CAPACIDAD_MAXIMA\n",
    "    )\n",
    "\n",
    "    ########\n",
    "    # 3º\n",
    "    ########\n",
    "\n",
    "    def drive_route(routes_df, nodo_entrada):\n",
    "        \"\"\"\n",
    "        Calcula el recorrido óptimo que pasa por todos los CIDs únicos en routes_df,\n",
    "        utilizando el grafo de conducción G_super y la función calcular_tiempo_drive.\n",
    "        \n",
    "        Args:\n",
    "        routes_df    : DataFrame con ['cid', 'travel_number', 'sequence', ...] que contiene las rutas.  \n",
    "        nodo_entrada : nodo por donde llega la furgoneta  \n",
    "        Returns:\n",
    "        cid_route    : DataFrame con las rutas entre los CIDs, tiempos y distancias calculados.\n",
    "        \"\"\"\n",
    "            \n",
    "\n",
    "        unique_cids = routes_df['cid'].unique()\n",
    "        N = len(unique_cids) + 1  # +1 porque también contamos con el nodo de depósito\n",
    "        time_matrix = [[0] * N for _ in range(N)]\n",
    "        \n",
    "        # Llenamos la matriz de tiempos entre todos los CIDs y el depósito\n",
    "        cid_to_index = {cid: idx + 1 for idx, cid in enumerate(unique_cids)}\n",
    "        cid_to_index['deposit'] = 0  # El nodo del depósito estará en la posición 0\n",
    "        \n",
    "        # Rellenar la matriz con los tiempos de conducción\n",
    "        for i, cid1 in enumerate([nodo_entrada] + list(unique_cids)):\n",
    "            for j, cid2 in enumerate([nodo_entrada] + list(unique_cids)):\n",
    "                if i != j:\n",
    "                    # Calculamos el tiempo de conducción entre los CIDs\n",
    "                    try:\n",
    "                        t_min, _ = calcular_tiempo_drive(G_super, cid1, cid2)\n",
    "                    except Exception:\n",
    "                        t_min = float('inf')  # Si hay un error, asignamos un valor infinito\n",
    "                    if np.isfinite(t_min):\n",
    "                        time_matrix[i][j] = int(math.ceil(t_min * 60))  # Convertimos minutos a segundos\n",
    "        \n",
    "        # 4) Resolver el TSP con OR-Tools\n",
    "        manager = pywrapcp.RoutingIndexManager(N, 1, 0)  # 1 vehículo, comenzamos desde el nodo 0 (depósito)\n",
    "        routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "        def time_callback(from_index, to_index):\n",
    "            # Llamada a la función para obtener el tiempo entre dos nodos\n",
    "            from_node = manager.IndexToNode(from_index)\n",
    "            to_node = manager.IndexToNode(to_index)\n",
    "            return time_matrix[from_node][to_node]\n",
    "\n",
    "        transit_callback_index = routing.RegisterTransitCallback(time_callback)\n",
    "        routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
    "\n",
    "        # Parámetros de búsqueda\n",
    "        search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "        search_parameters.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.SAVINGS\n",
    "        search_parameters.time_limit.seconds = 3  # Limitar el tiempo de búsqueda\n",
    "\n",
    "        # Resolvemos el problema de TSP\n",
    "        solution = routing.SolveWithParameters(search_parameters)\n",
    "        if not solution:\n",
    "            raise RuntimeError(\"No se pudo encontrar una solución para el TSP\")\n",
    "\n",
    "        # 5) Extraer la ruta óptima y calcular la distancia total\n",
    "        route_sequence = [nodo_entrada]  # Iniciamos con el nodo de depósito\n",
    "        total_time_sec = 0\n",
    "        total_distance_m = 0\n",
    "        idx = routing.Start(0)\n",
    "        \n",
    "        while not routing.IsEnd(idx):\n",
    "            node_index = manager.IndexToNode(idx)\n",
    "            cid = list(unique_cids)[node_index - 1]  # Obtener el CID correspondiente\n",
    "            route_sequence.append(cid)  # Agregar CID correspondiente\n",
    "            next_idx = solution.Value(routing.NextVar(idx))\n",
    "            total_time_sec += routing.GetArcCostForVehicle(idx, next_idx, 0)\n",
    "\n",
    "            # Calculamos la distancia entre los nodos\n",
    "            a, b = route_sequence[-2], route_sequence[-1]  # Usamos los últimos dos CIDs\n",
    "            _, path = calcular_tiempo_drive(G_super, a, b)\n",
    "            if path:\n",
    "                for u, w in zip(path[:-1], path[1:]):\n",
    "                    ed = G_super.get_edge_data(u, w)\n",
    "                    total_distance_m += min(e.get('length', 0) for e in ed.values())\n",
    "\n",
    "            idx = next_idx\n",
    "\n",
    "        # Añadimos el nodo de vuelta al inicio para cerrar la ruta\n",
    "\n",
    "        total_time_min = round(total_time_sec / 60, 3)\n",
    "        total_distance_km = round(total_distance_m / 1000, 3)\n",
    "\n",
    "        # 6) Crear el DataFrame con la ruta calculada\n",
    "        cid_route = {\n",
    "            'deposito': nodo_entrada,\n",
    "            'sequence': [[nodo_entrada] + route_sequence],  # Aquí se crea la lista de la columna 'cid'\n",
    "            'time_min': total_time_min,\n",
    "            'distance_km': total_distance_km\n",
    "        }\n",
    "\n",
    "        return cid_route\n",
    "\n",
    "    cid_route = drive_route(\n",
    "        routes_df, nodo_entrada)  \n",
    "    \n",
    "\n",
    "    ########\n",
    "    # 4º\n",
    "    ########\n",
    "\n",
    "    def calculate_results_m1(routes_df, cid_route):\n",
    "        \"\"\"\n",
    "        Calcula el coste total del reparto sumando costes fijos, por tiempo y por distancia.\n",
    "        \n",
    "        Args:\n",
    "            routes_df    : rutas andando\n",
    "            cid_route    : ruta furgone\n",
    "        \n",
    "        Returns:\n",
    "            total_cost   : Diccionario con los costes calculados.\n",
    "        \"\"\"\n",
    "            # Definición de las constantes fuera de la función\n",
    "        FIXED_DAILY_RATE_VAN      = 31.76   # €/día \n",
    "        TIME_HOURLY_RATE_VAN      = 21.19 + FIXED_DAILY_RATE_VAN / 8  # €/hora\n",
    "        DISTANCE_PER_KM_RATE_VAN  = 0.184   # €/km\n",
    "\n",
    "        total_kms_walk = routes_df['distance_km'].sum() \n",
    "        total_hours_walk = routes_df['time_min'].sum() / 60\n",
    "        total_kms_drive = cid_route['distance_km']\n",
    "        total_hours_drive = cid_route['time_min'] / 60\n",
    "\n",
    "        distance_cost_van = total_kms_drive * DISTANCE_PER_KM_RATE_VAN \n",
    "        distance_cost_ona = 0\n",
    "        time_cost_van = (total_hours_drive + total_hours_walk) * TIME_HOURLY_RATE_VAN\n",
    "        time_cost_ona = 0\n",
    "\n",
    "        results = {\n",
    "            'total_kms_walk': total_kms_walk,\n",
    "            'total_hours_walk': total_hours_walk,\n",
    "            'total_kms_drive': total_kms_drive,\n",
    "            'total_hours_drive': total_hours_drive,\n",
    "            'distance_cost_van': distance_cost_van,\n",
    "            'distance_cost_ona': distance_cost_ona,\n",
    "            'time_cost_van': time_cost_van,\n",
    "            'time_cost_ona': time_cost_ona,\n",
    "            'total_cost': distance_cost_van + time_cost_van + distance_cost_ona + time_cost_ona\n",
    "        }\n",
    "    \n",
    "        return {categoria: round(valor, 4)  for categoria, valor in results.items()}\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return calculate_results_m1(routes_df, cid_route)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f09b0",
   "metadata": {},
   "source": [
    "## Simulation M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da15f8ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def simulation_M2(df_comercios, nodo_entrada, nodos_almacenes, seed=None, CAPACIDAD_MAXIMA_ONA=20):\n",
    "    ########\n",
    "    # 1º\n",
    "    ########\n",
    "    def planificar_hub(nodo_entrada, nodos_almacenes,  percentil=50, seed=seed):\n",
    "        \"\"\"\n",
    "        Selecciona un hub de almacén cercano al centroide del grafo y calcula la ruta\n",
    "        desde un nodo de entrada hasta ese hub. Si el hub elegido falla, reintenta con\n",
    "        los demás candidatos.\n",
    "\n",
    "        Parámetros:\n",
    "        - nodo_entrada: Nodo inicial (depósito periférico) desde el que partimos.\n",
    "        - nodos_almacenes: Lista de nodos de almacenes.\n",
    "        - percentil: Percentil de almacenes más cercanos al centroide a considerar (por defecto 50).\n",
    "        - seed: Semilla para la aleatoriedad (opcional).\n",
    "\n",
    "        Retorna:\n",
    "        - dict con:\n",
    "            'depot'   : nodo_entrada,\n",
    "            'hub'     : nodo seleccionado con ruta válida,\n",
    "            't_drive' : tiempo de conducción al hub (en minutos),\n",
    "            'dist'    : distancia total (en km),\n",
    "            'camino'  : lista de nodos que forman la ruta\n",
    "        o None si ningún candidato tiene ruta.\n",
    "        \"\"\"\n",
    "        # Instanciamos un RNG local\n",
    "        rng = np.random.RandomState(seed)\n",
    "\n",
    "        # 1. Calcular el centroide usando todos los almacenes\n",
    "        xs = [G_super.nodes[n]['x'] for n in nodos_almacenes]\n",
    "        ys = [G_super.nodes[n]['y'] for n in nodos_almacenes]\n",
    "        centroide = Point(np.mean(xs), np.mean(ys))\n",
    "\n",
    "        # 2. Medir distancia euclídea de cada almacén al centroide\n",
    "        distancias = [\n",
    "            (n, centroide.distance(Point(G_super.nodes[n]['x'],\n",
    "                                        G_super.nodes[n]['y'])))\n",
    "            for n in nodos_almacenes\n",
    "        ]\n",
    "\n",
    "        # 3. Obtener los N más cercanos según el percentil\n",
    "        num_cand = math.ceil(len(distancias) * (percentil / 100))\n",
    "        candidatos = sorted(distancias, key=lambda x: x[1])[:num_cand]\n",
    "        almacenes_cercanos = [n for n, _ in candidatos]\n",
    "\n",
    "        # 4. Intentar cada hub en orden aleatorio hasta encontrar ruta válida\n",
    "        for hub in rng.choice(almacenes_cercanos,size=len(almacenes_cercanos),\n",
    "        replace=False):\n",
    "            try:\n",
    "                t_drive, camino = calcular_tiempo_drive(G_super, nodo_entrada, hub)\n",
    "                if np.isfinite(t_drive):\n",
    "                    distancia_m = sum(\n",
    "                        G_super.get_edge_data(u, v)[0]['length']\n",
    "                        for u, v in zip(camino[:-1], camino[1:])\n",
    "                    )\n",
    "                    return {\n",
    "                        'depot': nodo_entrada,\n",
    "                        'hub': hub,\n",
    "                        't_drive': t_drive,\n",
    "                        'dist': distancia_m / 1000,\n",
    "                        'camino': camino\n",
    "                    }\n",
    "            except nx.NetworkXNoPath:\n",
    "                # Este hub no conecta, pasamos al siguiente candidato\n",
    "                continue\n",
    "\n",
    "        # Si agotamos todos los candidatos sin éxito:\n",
    "        print(f\"❌ Ningún hub de los {len(almacenes_cercanos)} candidatos tuvo ruta válida.\")\n",
    "        return None\n",
    "\n",
    "    hub_route = planificar_hub(nodo_entrada, nodos_almacenes, percentil=50, seed=seed)\n",
    "\n",
    "    ########\n",
    "    # 2º\n",
    "    ########\n",
    "\n",
    "    K_MIN   = 2\n",
    "    K_MAX   = 10\n",
    "    ALPHA   = 0.25  # peso Silhouette\n",
    "    BETA    = 0.25  # peso Inertia\n",
    "    GAMMA   = 0.5  # peso Balance de capacidad\n",
    "\n",
    "    def clustering(df_comercios, hub_route, cap_max=CAPACIDAD_MAXIMA_ONA, k_min=2, k_max=10, alpha=0.2, beta=0.2, gamma=0.6, seed = seed, view=False):\n",
    "        \"\"\"\n",
    "        Clustering de los comercios usando K-Medoids, evaluando el mejor número de clústeres con el\n",
    "        método combinado de Silhouette, Inertia, y Balance de Capacidad, con ponderaciones.\n",
    "\n",
    "        Args:\n",
    "        df_comercios    : DataFrame con ['node', 'paquetes', 'geometry', 'grupo_repartidor'].\n",
    "        hub_route           : Info del hub, para calcular la distancia de balance de capacidad.\n",
    "        cap_max         : Capacidad máxima de la ruta para el balance.\n",
    "        k_min           : Número mínimo de clústeres.\n",
    "        k_max           : Número máximo de clústeres.\n",
    "        alpha           : Peso del índice Silhouette.\n",
    "        beta            : Peso de la Inertia.\n",
    "        gamma           : Peso del balance de capacidad.\n",
    "        seed            : Semilla para la aleatoriedad (opcional).\n",
    "\n",
    "        Returns:\n",
    "        best_k          : El mejor número de clústeres encontrado.\n",
    "        \"\"\"\n",
    "\n",
    "        # 1) Extraemos las coordenadas y demandas\n",
    "        coords = np.vstack([df_comercios.geometry.x.values, df_comercios.geometry.y.values]).T\n",
    "        hub = hub_route['hub']\n",
    "        hub_coord = (G_super.nodes[hub]['x'], G_super.nodes[hub]['y'])\n",
    "        demands = df_comercios['paquetes'].to_numpy()\n",
    "\n",
    "        ks, sils, ines, balances = [], [], [], []\n",
    "        hub_x, hub_y = hub_coord\n",
    "\n",
    "        for k in range(k_min, min(k_max + 1, len(df_comercios))):\n",
    "            # 2) Entrenamos K-Medoids\n",
    "            kmed = KMedoids(n_clusters=k, init='k-medoids++', method='pam', metric='euclidean', random_state=seed)\n",
    "            labels = kmed.fit_predict(coords)\n",
    "\n",
    "            # 3) Calculamos el índice de Silhouette\n",
    "            sil = silhouette_score(coords, labels) if k > 1 else 0\n",
    "\n",
    "            # 4) Calculamos la Inertia manualmente usando las posiciones de los medoids\n",
    "            medoids = coords[kmed.medoid_indices_]\n",
    "            inertia = sum(np.sum((coords[labels == j] - medoids[j]) ** 2) for j in range(k))\n",
    "\n",
    "            # 5) Balance de capacidad\n",
    "            loads = np.array([demands[labels == j].sum() for j in range(k)])\n",
    "            mults = np.ceil(loads / cap_max) * cap_max\n",
    "            errors = (loads - mults) ** 2\n",
    "            bal = np.mean(errors)\n",
    "\n",
    "            ks.append(k)\n",
    "            sils.append(sil)\n",
    "            ines.append(inertia)\n",
    "            balances.append(bal)\n",
    "\n",
    "        # 6) Escalado robusto de las métricas\n",
    "        scaler = RobustScaler()\n",
    "        sil_r = scaler.fit_transform(np.array(sils).reshape(-1, 1)).ravel()\n",
    "        ine_r = -scaler.fit_transform(np.array(ines).reshape(-1, 1)).ravel()\n",
    "        bal_r = -scaler.fit_transform(np.array(balances).reshape(-1, 1)).ravel()\n",
    "\n",
    "        # 7) Combinamos las métricas con penalización por número de clústeres\n",
    "        combined = alpha * sil_r + beta * ine_r + gamma * bal_r\n",
    "        best_idx = np.argmax(combined)\n",
    "        best_k = ks[best_idx]\n",
    "\n",
    "        if view:\n",
    "            # 8) Visualización del diagnóstico\n",
    "            fig, ax = plt.subplots(figsize=(15, 10))\n",
    "            ax.plot(ks, sil_r, marker='o', label='Silhouette')\n",
    "            ax.plot(ks, ine_r, marker='s', label='– Inertia')\n",
    "            ax.plot(ks, bal_r, marker='d', label='– Capacity Balance')\n",
    "            ax.plot(ks, combined, marker='^', lw=2, color='black', label='Combined')\n",
    "            ax.axvline(best_k, ls='--', color='gray', label=f'Best k = {best_k}')\n",
    "            ax.set(xlabel='k', ylabel='Score', title='k selection with K-Medoids + RobustScaler')\n",
    "            ax.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # 9) Clustering final con el mejor k encontrado\n",
    "        kmed = KMedoids(n_clusters=best_k, init='k-medoids++', method='pam', metric='euclidean', random_state=seed)\n",
    "        labels = kmed.fit_predict(coords)\n",
    "        df_comercios['grupo_repartidor'] = labels + 1  \n",
    "        \n",
    "        return best_k, df_comercios\n",
    "\n",
    "    # Ejemplo de uso\n",
    "    best_k, df_comercios = clustering(df_comercios, hub_route, CAPACIDAD_MAXIMA_ONA, view=False)\n",
    "\n",
    "    ########\n",
    "    # 3º\n",
    "    ########   \n",
    "\n",
    "    def cluster_routes(df_comercios, hub_route, CAPACIDAD_MAXIMA=CAPACIDAD_MAXIMA_ONA):\n",
    "        \"\"\"\n",
    "        Calcular rutas de entrega para cada grupo de repartidor usando CVRP con OR-Tools,\n",
    "        tiempos en segundos, manejo de 'inf' y cómputo de distancia recorrida por ruta.\n",
    "        \n",
    "        Args:\n",
    "        df_comercios     : DataFrame con ['node', 'paquetes', 'geometry', 'grupo_repartidor'].\n",
    "        capacidad_maxima : int, capacidad máxima de paquetes por ruta.\n",
    "        \n",
    "        Returns:\n",
    "        routes_df        : DataFrame con rutas por cada grupo de repartidor ['grupo_repartidor', 'sequence', 'time_min', 'distance_km', 'load'].\n",
    "        \"\"\"\n",
    "        \n",
    "        all_routes = []\n",
    "        total_time_sec = 0\n",
    "        total_batches = 0\n",
    "        INF_SEC = 10**9  # Valor para distancias infinitas (cuando no hay conexión)\n",
    "        \n",
    "        # Agrupar comercios por 'grupo_repartidor'\n",
    "        grupos_repartidor = df_comercios['grupo_repartidor'].unique()\n",
    "        \n",
    "        # Iteramos sobre cada grupo de repartidor\n",
    "        for grupo_sel in grupos_repartidor:\n",
    "            # Filtrar comercios de ese grupo\n",
    "            sub_bajos = df_comercios[df_comercios['grupo_repartidor'] == grupo_sel]\n",
    "            N = len(sub_bajos) + 1\n",
    "            \n",
    "            # Si no hay comercios para este grupo, continuar con el siguiente\n",
    "            if N == 0:\n",
    "                continue\n",
    "            \n",
    "            # 1) Nodos y demandas (los comercios dentro del grupo + el hub)\n",
    "            hub = hub_route['hub']  # El nodo del hub\n",
    "            locations = list(sub_bajos['node'])  # Los nodos de comercios\n",
    "            locations.insert(0, hub)  # Añadir el hub como punto de inicio\n",
    "            demands = list(sub_bajos['paquetes'])  # Demandas de paquetes\n",
    "            demands.insert(0, 0)  # El hub tiene demanda cero\n",
    "            \n",
    "            # 2) Matriz de tiempos (segundos) entre los comercios\n",
    "            time_matrix = [[0]*N for _ in range(N)]\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    try:\n",
    "                        t_min, _ = calcular_tiempo_walk(G_super, locations[i], locations[j])  # Intentamos con G_super\n",
    "                    except Exception:\n",
    "                        t_min = INF_SEC  # Si no hay ruta, marcarlo como \"infinito\"\n",
    "                    time_matrix[i][j] = INF_SEC if not np.isfinite(t_min) else int(math.ceil(t_min * 60))  # Convertir a minutos\n",
    "            \n",
    "            # 3) Número de rutas necesarias\n",
    "            total_demand = sum(demands)\n",
    "            R = math.ceil(total_demand / CAPACIDAD_MAXIMA)  # El número de rutas necesarias\n",
    "            \n",
    "            # 4) Configurar OR-Tools para el problema de CVRP\n",
    "            manager = pywrapcp.RoutingIndexManager(N, R, 0)\n",
    "            routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "            def time_callback(f, t):\n",
    "                return time_matrix[manager.IndexToNode(f)][manager.IndexToNode(t)]\n",
    "            \n",
    "            cb_t = routing.RegisterTransitCallback(time_callback)\n",
    "            routing.SetArcCostEvaluatorOfAllVehicles(cb_t)\n",
    "\n",
    "            def demand_callback(idx):\n",
    "                return demands[manager.IndexToNode(idx)]\n",
    "            \n",
    "            cb_d = routing.RegisterUnaryTransitCallback(demand_callback)\n",
    "            routing.AddDimensionWithVehicleCapacity(cb_d, 0, [CAPACIDAD_MAXIMA+1]*R, True, \"Capacity\")\n",
    "\n",
    "            search_params = pywrapcp.DefaultRoutingSearchParameters()\n",
    "            search_params.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.SAVINGS\n",
    "            search_params.time_limit.seconds = 15\n",
    "\n",
    "            # Resolver el problema con OR-Tools\n",
    "            try:\n",
    "                sol = routing.SolveWithParameters(search_params)\n",
    "                if not sol:\n",
    "                    raise RuntimeError(f\"No solution CVRP for group {grupo_sel}\")\n",
    "            except RuntimeError:\n",
    "                print(f\"❌ Error: No se encontró solución para el grupo {grupo_sel}.\")\n",
    "                continue\n",
    "\n",
    "            # 5) Extraer rutas y calcular distancia\n",
    "            for v in range(R):\n",
    "                idx = routing.Start(v)\n",
    "                if routing.IsEnd(sol.Value(routing.NextVar(idx))):\n",
    "                    continue\n",
    "                seq_nodes = []\n",
    "                load = 0\n",
    "                time_sec = 0\n",
    "                dist_m = 0.0\n",
    "                # Construir la ruta\n",
    "                while not routing.IsEnd(idx):\n",
    "                    n = manager.IndexToNode(idx)\n",
    "                    seq_nodes.append(locations[n])\n",
    "                    load += demands[n]\n",
    "                    nxt = sol.Value(routing.NextVar(idx))\n",
    "                    time_sec += routing.GetArcCostForVehicle(idx, nxt, v)\n",
    "\n",
    "                    # Calcular la distancia tramo a tramo\n",
    "                    a, b = locations[n], locations[manager.IndexToNode(nxt)]\n",
    "                    _, path = calcular_tiempo_walk(G_super, a, b)  # Usamos G_super para la distancia\n",
    "                    if path:\n",
    "                        for u, w in zip(path[:-1], path[1:]):\n",
    "                            ed = G_super.get_edge_data(u, w)\n",
    "                            dist_m += min(e.get('length', 0) for e in ed.values())\n",
    "\n",
    "                    idx = nxt\n",
    "\n",
    "                # Retorno opcional al depósito (hub)\n",
    "                seq_nodes.append(hub)\n",
    "\n",
    "                # Almacenar resultados\n",
    "                all_routes.append({\n",
    "                    'grupo_repartidor': grupo_sel,\n",
    "                    'sequence': seq_nodes,\n",
    "                    'time_min': round(time_sec / 60, 3),\n",
    "                    'distance_km': round(dist_m / 1000, 3),\n",
    "                    'load': load\n",
    "                })\n",
    "                total_time_sec += time_sec\n",
    "                total_batches += 1\n",
    "\n",
    "        # Crear un DataFrame con los resultados\n",
    "        routes_df = pd.DataFrame(all_routes)\n",
    "        return routes_df\n",
    "\n",
    "    # === Ejemplo de uso ===\n",
    "    routes_df = cluster_routes(df_comercios, hub_route, CAPACIDAD_MAXIMA_ONA)\n",
    "\n",
    "\n",
    "    def calculate_results_m2(routes_df, hub_route):\n",
    "        \"\"\"\n",
    "        Calcula el coste total del reparto sumando costes fijos, por tiempo y por distancia, \n",
    "        diferenciando entre las rutas desde el **depósito al CID** (furgoneta) y las rutas \n",
    "        desde el **CID al hub** (ONA).\n",
    "        \n",
    "        Args:\n",
    "            routes_df    : DataFrame con ['time_min', 'distance_km', 'grupo_repartidor'] de las rutas generadas.\n",
    "            hub_route   : Información del camino entre el depósito y el hub, incluyendo tiempo y distancia.\n",
    "        \n",
    "        Returns:\n",
    "            total_cost   : Coste total calculado, que incluye los costes fijos, por tiempo y por distancia.\n",
    "        \"\"\"\n",
    "        # Definición de las constantes fuera de la función\n",
    "        FIXED_DAILY_RATE_VAN      = 31.76   # €/día\n",
    "        TIME_HOURLY_RATE_VAN      = 21.19 + FIXED_DAILY_RATE_VAN / 8  # €/hora\n",
    "        DISTANCE_PER_KM_RATE_VAN  = 0.184   # €/km\n",
    "\n",
    "        FIXED_DAILY_RATE_ONA      = 35.42   # €/día\n",
    "        TIME_HOURLY_RATE_ONA      = 9.58 + FIXED_DAILY_RATE_ONA / 8  # €/hora\n",
    "        DISTANCE_PER_KM_RATE_ONA  = 0.055   # €/km\n",
    "        total_kms_walk = routes_df['distance_km'].sum() \n",
    "        total_hours_walk = routes_df['time_min'].sum() / 60 \n",
    "        total_kms_drive = hub_route['dist']\n",
    "        total_hours_drive = hub_route['t_drive'] / 60\n",
    "\n",
    "        distance_cost_van = total_kms_drive * DISTANCE_PER_KM_RATE_VAN \n",
    "        distance_cost_ona = total_kms_walk * DISTANCE_PER_KM_RATE_ONA\n",
    "        time_cost_van = total_hours_drive * TIME_HOURLY_RATE_VAN\n",
    "        time_cost_ona = total_hours_walk * TIME_HOURLY_RATE_ONA\n",
    "        \n",
    "        results = {\n",
    "            'total_kms_walk': total_kms_walk,\n",
    "            'total_hours_walk': total_hours_walk,\n",
    "            'total_kms_drive': total_kms_drive,\n",
    "            'total_hours_drive': total_hours_drive,\n",
    "            'distance_cost_van': distance_cost_van,\n",
    "            'distance_cost_ona': distance_cost_ona,\n",
    "            'time_cost_van': time_cost_van,\n",
    "            'time_cost_ona': time_cost_ona,\n",
    "            'total_cost': distance_cost_van + time_cost_van + distance_cost_ona + time_cost_ona\n",
    "        }\n",
    "\n",
    "        return {categoria: round(valor, 4)  for categoria, valor in results.items()}\n",
    "    \n",
    "    return calculate_results_m2(routes_df, hub_route)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a85b3a",
   "metadata": {},
   "source": [
    "## Simulation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0426eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2b698017c84718afc84e0f309bcc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Barrios:   0%|          | 0/63 [00:00<?, ? barrio/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando barrio «MONTOLIVET»… ✅ Supergraph MONTOLIVET created: 1371 nodes, 3632 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) \n",
      "✔ Resultados del barrio «MONTOLIVET» guardados.\n",
      "\n",
      "Procesando barrio «CASTELLAR-L'OLIVERAL»… ✅ Supergraph CASTELLAR-L'OLIVERAL created: 1459 nodes, 3600 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) \n",
      "✔ Resultados del barrio «CASTELLAR-L'OLIVERAL» guardados.\n",
      "\n",
      "Procesando barrio «PINEDO»… ✅ Supergraph PINEDO created: 961 nodes, 2134 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) \n",
      "✔ Resultados del barrio «PINEDO» guardados.\n",
      "\n",
      "Procesando barrio «SANT MARCEL.LI»… ✅ Supergraph SANT MARCEL.LI created: 809 nodes, 1968 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) \n",
      "✔ Resultados del barrio «SANT MARCEL.LI» guardados.\n",
      "\n",
      "Procesando barrio «LA PETXINA»… ✅ Supergraph LA PETXINA created: 1428 nodes, 3536 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) ✅ (300, 1) ✅ (300, 2) ✅ (300, 3) ✅ (300, 4) ✅ (300, 5) ✅ (350, 1) ✅ (350, 2) ✅ (350, 3) ✅ (350, 4) ✅ (350, 5) ✅ (400, 1) ✅ (400, 2) ✅ (400, 3) ✅ (400, 4) ✅ (400, 5) ✅ (450, 1) ✅ (450, 2) ✅ (450, 3) ✅ (450, 4) ✅ (450, 5) ✅ (500, 1) ✅ (500, 2) ✅ (500, 3) ✅ (500, 4) ✅ (500, 5) ✅ (550, 1) ✅ (550, 2) ✅ (550, 3) ✅ (550, 4) ✅ (550, 5) ✅ (600, 1) ✅ (600, 2) ✅ (600, 3) ✅ (600, 4) ✅ (600, 5) ✅ (650, 1) ✅ (650, 2) ✅ (650, 3) ✅ (650, 4) ✅ (650, 5) ✅ (700, 1) ✅ (700, 2) ✅ (700, 3) ✅ (700, 4) ✅ (700, 5) ✅ (750, 1) ✅ (750, 2) ✅ (750, 3) ✅ (750, 4) ✅ (750, 5) ✅ (800, 1) ✅ (800, 2) ✅ (800, 3) ✅ (800, 4) ✅ (800, 5) ✅ (850, 1) ✅ (850, 2) ✅ (850, 3) ✅ (850, 4) ✅ (850, 5) ✅ (900, 1) ✅ (900, 2) ✅ (900, 3) ✅ (900, 4) ✅ (900, 5) ✅ (950, 1) ✅ (950, 2) ✅ (950, 3) ✅ (950, 4) ✅ (950, 5) ✅ (1000, 1) ✅ (1000, 2) ✅ (1000, 3) ✅ (1000, 4) ✅ (1000, 5) ✅ (1050, 1) ✅ (1050, 2) ✅ (1050, 3) ✅ (1050, 4) ✅ (1050, 5) \n",
      "✔ Resultados del barrio «LA PETXINA» guardados.\n",
      "\n",
      "Procesando barrio «JAUME ROIG»… ✅ Supergraph JAUME ROIG created: 691 nodes, 1720 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) \n",
      "✔ Resultados del barrio «JAUME ROIG» guardados.\n",
      "\n",
      "Procesando barrio «BENICALAP»… ✅ Supergraph BENICALAP created: 3776 nodes, 9916 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) ✅ (300, 1) ✅ (300, 2) ✅ (300, 3) ✅ (300, 4) ✅ (300, 5) ✅ (350, 1) ✅ (350, 2) ✅ (350, 3) ✅ (350, 4) ✅ (350, 5) ✅ (400, 1) ✅ (400, 2) ✅ (400, 3) ✅ (400, 4) ✅ (400, 5) ✅ (450, 1) ✅ (450, 2) ✅ (450, 3) ✅ (450, 4) ✅ (450, 5) ✅ (500, 1) ✅ (500, 2) ✅ (500, 3) ✅ (500, 4) ✅ (500, 5) ✅ (550, 1) ✅ (550, 2) ✅ (550, 3) ✅ (550, 4) ✅ (550, 5) ✅ (600, 1) ✅ (600, 2) ✅ (600, 3) ✅ (600, 4) ✅ (600, 5) ✅ (650, 1) ✅ (650, 2) ✅ (650, 3) ✅ (650, 4) ✅ (650, 5) ✅ (700, 1) ✅ (700, 2) ✅ (700, 3) ✅ (700, 4) ✅ (700, 5) ✅ (750, 1) ✅ (750, 2) ✅ (750, 3) ✅ (750, 4) ✅ (750, 5) ✅ (800, 1) ✅ (800, 2) ✅ (800, 3) ✅ (800, 4) ✅ (800, 5) ✅ (850, 1) ✅ (850, 2) ✅ (850, 3) ✅ (850, 4) ✅ (850, 5) ✅ (900, 1) ✅ (900, 2) ✅ (900, 3) ✅ (900, 4) ✅ (900, 5) ✅ (950, 1) ✅ (950, 2) ✅ (950, 3) ✅ (950, 4) ✅ (950, 5) ✅ (1000, 1) ✅ (1000, 2) ✅ (1000, 3) ✅ (1000, 4) ✅ (1000, 5) ✅ (1050, 1) ✅ (1050, 2) ✅ (1050, 3) ✅ (1050, 4) ✅ (1050, 5) \n",
      "✔ Resultados del barrio «BENICALAP» guardados.\n",
      "\n",
      "Procesando barrio «MALILLA»… ✅ Supergraph MALILLA created: 3972 nodes, 10060 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) \n",
      "✔ Resultados del barrio «MALILLA» guardados.\n",
      "\n",
      "Procesando barrio «SANT ISIDRE»… ✅ Supergraph SANT ISIDRE created: 1009 nodes, 2420 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) \n",
      "✔ Resultados del barrio «SANT ISIDRE» guardados.\n",
      "\n",
      "Procesando barrio «SAFRANAR»… ✅ Supergraph SAFRANAR created: 1271 nodes, 3280 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) \n",
      "✔ Resultados del barrio «SAFRANAR» guardados.\n",
      "\n",
      "Procesando barrio «LA RAIOSA»… ✅ Supergraph LA RAIOSA created: 1128 nodes, 2810 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) ✅ (300, 1) ✅ (300, 2) ✅ (300, 3) ✅ (300, 4) ✅ (300, 5) ✅ (350, 1) ✅ (350, 2) ✅ (350, 3) ✅ (350, 4) ✅ (350, 5) ✅ (400, 1) ✅ (400, 2) ✅ (400, 3) ✅ (400, 4) ✅ (400, 5) ✅ (450, 1) ✅ (450, 2) ✅ (450, 3) ✅ (450, 4) ✅ (450, 5) ✅ (500, 1) ✅ (500, 2) ✅ (500, 3) ✅ (500, 4) ✅ (500, 5) ✅ (550, 1) ✅ (550, 2) ✅ (550, 3) ✅ (550, 4) ✅ (550, 5) ✅ (600, 1) ✅ (600, 2) ✅ (600, 3) ✅ (600, 4) ✅ (600, 5) ✅ (650, 1) ✅ (650, 2) ✅ (650, 3) ✅ (650, 4) ✅ (650, 5) ✅ (700, 1) ✅ (700, 2) ✅ (700, 3) ✅ (700, 4) ✅ (700, 5) ✅ (750, 1) ✅ (750, 2) ✅ (750, 3) ✅ (750, 4) ✅ (750, 5) ✅ (800, 1) ✅ (800, 2) ✅ (800, 3) ✅ (800, 4) ✅ (800, 5) \n",
      "✔ Resultados del barrio «LA RAIOSA» guardados.\n",
      "\n",
      "Procesando barrio «CAMI FONDO»… ✅ Supergraph CAMI FONDO created: 321 nodes, 784 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) \n",
      "✔ Resultados del barrio «CAMI FONDO» guardados.\n",
      "\n",
      "Procesando barrio «LA GRAN VIA»… ✅ Supergraph LA GRAN VIA created: 1247 nodes, 3024 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) ✅ (300, 1) ✅ (300, 2) ✅ (300, 3) ✅ (300, 4) ✅ (300, 5) ✅ (350, 1) ✅ (350, 2) ✅ (350, 3) ✅ (350, 4) ✅ (350, 5) ✅ (400, 1) ✅ (400, 2) ✅ (400, 3) ✅ (400, 4) ✅ (400, 5) ✅ (450, 1) ✅ (450, 2) ✅ (450, 3) ✅ (450, 4) ✅ (450, 5) ✅ (500, 1) ✅ (500, 2) ✅ (500, 3) ✅ (500, 4) ✅ (500, 5) ✅ (550, 1) ✅ (550, 2) ✅ (550, 3) ✅ (550, 4) ✅ (550, 5) ✅ (600, 1) ✅ (600, 2) ✅ (600, 3) ✅ (600, 4) ✅ (600, 5) ✅ (650, 1) ✅ (650, 2) ✅ (650, 3) ✅ (650, 4) ✅ (650, 5) ✅ (700, 1) ✅ (700, 2) ✅ (700, 3) ✅ (700, 4) ✅ (700, 5) ✅ (750, 1) ✅ (750, 2) ✅ (750, 3) ✅ (750, 4) ✅ (750, 5) ✅ (800, 1) ✅ (800, 2) ✅ (800, 3) ✅ (800, 4) ✅ (800, 5) ✅ (850, 1) ✅ (850, 2) ✅ (850, 3) ✅ (850, 4) ✅ (850, 5) ✅ (900, 1) ✅ (900, 2) ✅ (900, 3) ✅ (900, 4) ✅ (900, 5) \n",
      "✔ Resultados del barrio «LA GRAN VIA» guardados.\n",
      "\n",
      "Procesando barrio «LA ROQUETA»… ✅ Supergraph LA ROQUETA created: 724 nodes, 1722 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) ✅ (300, 1) ✅ (300, 2) ✅ (300, 3) ✅ (300, 4) ✅ (300, 5) ✅ (350, 1) ✅ (350, 2) ✅ (350, 3) ✅ (350, 4) ✅ (350, 5) ✅ (400, 1) ✅ (400, 2) ✅ (400, 3) ✅ (400, 4) ✅ (400, 5) ✅ (450, 1) ✅ (450, 2) ✅ (450, 3) ✅ (450, 4) ✅ (450, 5) ✅ (500, 1) ✅ (500, 2) ✅ (500, 3) ✅ (500, 4) ✅ (500, 5) ✅ (550, 1) ✅ (550, 2) ✅ (550, 3) ✅ (550, 4) ✅ (550, 5) ✅ (600, 1) ✅ (600, 2) ✅ (600, 3) ✅ (600, 4) ✅ (600, 5) \n",
      "✔ Resultados del barrio «LA ROQUETA» guardados.\n",
      "\n",
      "Procesando barrio «EL MERCAT»… ✅ Supergraph EL MERCAT created: 1026 nodes, 2488 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) ✅ (300, 1) ✅ (300, 2) ✅ (300, 3) ✅ (300, 4) ✅ (300, 5) ✅ (350, 1) ✅ (350, 2) ✅ (350, 3) ✅ (350, 4) ✅ (350, 5) ✅ (400, 1) ✅ (400, 2) ✅ (400, 3) ✅ (400, 4) ✅ (400, 5) ✅ (450, 1) ✅ (450, 2) ✅ (450, 3) ✅ (450, 4) ✅ (450, 5) ✅ (500, 1) ✅ (500, 2) ✅ (500, 3) ✅ (500, 4) ✅ (500, 5) ✅ (550, 1) ✅ (550, 2) ✅ (550, 3) ✅ (550, 4) ✅ (550, 5) ✅ (600, 1) ✅ (600, 2) ✅ (600, 3) ✅ (600, 4) ✅ (600, 5) ✅ (650, 1) ✅ (650, 2) ✅ (650, 3) ✅ (650, 4) ✅ (650, 5) \n",
      "✔ Resultados del barrio «EL MERCAT» guardados.\n",
      "\n",
      "Procesando barrio «LES TENDETES»… ✅ Supergraph LES TENDETES created: 746 nodes, 1904 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) \n",
      "✔ Resultados del barrio «LES TENDETES» guardados.\n",
      "\n",
      "Procesando barrio «EL CALVARI»… ✅ Supergraph EL CALVARI created: 425 nodes, 992 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) \n",
      "✔ Resultados del barrio «EL CALVARI» guardados.\n",
      "\n",
      "Procesando barrio «LA MALVA-ROSA»… ✅ Supergraph LA MALVA-ROSA created: 842 nodes, 2246 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ❌ Error: No se encontró solución para el grupo 3.\n",
      "✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) \n",
      "✔ Resultados del barrio «LA MALVA-ROSA» guardados.\n",
      "\n",
      "Procesando barrio «NOU MOLES»… ✅ Supergraph NOU MOLES created: 1775 nodes, 4314 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) ✅ (300, 1) ✅ (300, 2) ✅ (300, 3) ✅ (300, 4) ✅ (300, 5) ✅ (350, 1) ✅ (350, 2) ✅ (350, 3) ✅ (350, 4) ✅ (350, 5) \n",
      "✔ Resultados del barrio «NOU MOLES» guardados.\n",
      "\n",
      "Procesando barrio «CIUTAT FALLERA»… ✅ Supergraph CIUTAT FALLERA created: 1119 nodes, 2662 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) \n",
      "✔ Resultados del barrio «CIUTAT FALLERA» guardados.\n",
      "\n",
      "Procesando barrio «SANT LLORENS»… ✅ Supergraph SANT LLORENS created: 1521 nodes, 3760 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) \n",
      "✔ Resultados del barrio «SANT LLORENS» guardados.\n",
      "\n",
      "Procesando barrio «BENIMAMET»… ✅ Supergraph BENIMAMET created: 2975 nodes, 7140 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) ✅ (300, 1) ✅ (300, 2) ✅ (300, 3) ✅ (300, 4) ✅ (300, 5) ✅ (350, 1) ✅ (350, 2) ✅ (350, 3) ✅ (350, 4) ✅ (350, 5) \n",
      "✔ Resultados del barrio «BENIMAMET» guardados.\n",
      "\n",
      "Procesando barrio «CAMI REAL»… ✅ Supergraph CAMI REAL created: 961 nodes, 2152 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) \n",
      "✔ Resultados del barrio «CAMI REAL» guardados.\n",
      "\n",
      "Procesando barrio «FAVARA»… ✅ Supergraph FAVARA created: 384 nodes, 958 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) \n",
      "✔ Resultados del barrio «FAVARA» guardados.\n",
      "\n",
      "Procesando barrio «AIORA»… ✅ Supergraph AIORA created: 1602 nodes, 4054 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) ✅ (300, 1) ✅ (300, 2) ✅ (300, 3) ✅ (300, 4) ✅ (300, 5) ✅ (350, 1) ✅ (350, 2) ✅ (350, 3) ✅ (350, 4) ✅ (350, 5) ✅ (400, 1) ✅ (400, 2) ✅ (400, 3) ✅ (400, 4) ✅ (400, 5) ✅ (450, 1) ✅ (450, 2) ✅ (450, 3) ✅ (450, 4) ✅ (450, 5) ✅ (500, 1) ✅ (500, 2) ✅ (500, 3) ✅ (500, 4) ✅ (500, 5) ✅ (550, 1) ✅ (550, 2) ✅ (550, 3) ✅ (550, 4) ✅ (550, 5) ✅ (600, 1) ✅ (600, 2) ✅ (600, 3) ✅ (600, 4) ✅ (600, 5) ✅ (650, 1) ✅ (650, 2) ✅ (650, 3) ✅ (650, 4) ✅ (650, 5) ✅ (700, 1) ✅ (700, 2) ✅ (700, 3) ✅ (700, 4) ✅ (700, 5) ✅ (750, 1) ✅ (750, 2) ✅ (750, 3) ✅ (750, 4) ✅ (750, 5) ✅ (800, 1) ✅ (800, 2) ✅ (800, 3) ✅ (800, 4) ✅ (800, 5) ✅ (850, 1) ✅ (850, 2) ✅ (850, 3) ✅ (850, 4) ✅ (850, 5) ✅ (900, 1) ✅ (900, 2) ✅ (900, 3) ✅ (900, 4) ✅ (900, 5) \n",
      "✔ Resultados del barrio «AIORA» guardados.\n",
      "\n",
      "Procesando barrio «LA SEU»… ✅ Supergraph LA SEU created: 721 nodes, 1736 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) ✅ (300, 1) ✅ (300, 2) ✅ (300, 3) ✅ (300, 4) ✅ (300, 5) ✅ (350, 1) ✅ (350, 2) ✅ (350, 3) ✅ (350, 4) ✅ (350, 5) ✅ (400, 1) ✅ (400, 2) ✅ (400, 3) ✅ (400, 4) ✅ (400, 5) \n",
      "✔ Resultados del barrio «LA SEU» guardados.\n",
      "\n",
      "Procesando barrio «SANT PAU»… ✅ Supergraph SANT PAU created: 4320 nodes, 10526 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) \n",
      "✔ Resultados del barrio «SANT PAU» guardados.\n",
      "\n",
      "Procesando barrio «LA CREU DEL GRAU»… ✅ Supergraph LA CREU DEL GRAU created: 647 nodes, 1648 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) ✅ (300, 1) ✅ (300, 2) ✅ (300, 3) ✅ (300, 4) ✅ (300, 5) ✅ (350, 1) ❌ Error: No se encontró solución para el grupo 2.\n",
      "✅ (350, 2) ✅ (350, 3) ✅ (350, 4) ✅ (350, 5) \n",
      "✔ Resultados del barrio «LA CREU DEL GRAU» guardados.\n",
      "\n",
      "Procesando barrio «RUSSAFA»… ✅ Supergraph RUSSAFA created: 2237 nodes, 5316 edges.\n",
      "✅ (50, 1) ✅ (50, 2) ✅ (50, 3) ✅ (50, 4) ✅ (50, 5) ✅ (100, 1) ✅ (100, 2) ✅ (100, 3) ✅ (100, 4) ✅ (100, 5) ✅ (150, 1) ✅ (150, 2) ✅ (150, 3) ✅ (150, 4) ✅ (150, 5) ✅ (200, 1) ✅ (200, 2) ✅ (200, 3) ✅ (200, 4) ✅ (200, 5) ✅ (250, 1) ✅ (250, 2) ✅ (250, 3) ✅ (250, 4) ✅ (250, 5) ✅ (300, 1) ✅ (300, 2) ✅ (300, 3) ✅ (300, 4) ✅ (300, 5) ✅ (350, 1) ✅ (350, 2) ✅ (350, 3) ✅ (350, 4) ✅ (350, 5) ✅ (400, 1) ✅ (400, 2) ✅ (400, 3) ✅ (400, 4) ✅ (400, 5) ✅ (450, 1) ✅ (450, 2) ✅ (450, 3) ✅ (450, 4) ✅ (450, 5) ✅ (500, 1) ✅ (500, 2) ✅ (500, 3) ✅ (500, 4) ✅ (500, 5) ✅ (550, 1) ✅ (550, 2) ✅ (550, 3) ✅ (550, 4) ✅ (550, 5) ✅ (600, 1) ✅ (600, 2) ✅ (600, 3) ✅ (600, 4) ✅ (600, 5) ✅ (650, 1) ✅ (650, 2) ✅ (650, 3) ✅ (650, 4) ✅ (650, 5) ✅ (700, 1) ✅ (700, 2) ✅ (700, 3) ✅ (700, 4) ✅ (700, 5) ✅ (750, 1) ✅ (750, 2) ✅ (750, 3) ✅ (750, 4) ✅ (750, 5) ✅ (800, 1) ✅ (800, 2) ✅ (800, 3) ✅ (800, 4) ✅ (800, 5) ✅ (850, 1) ✅ (850, 2) ✅ (850, 3) ✅ (850, 4) ✅ (850, 5) ✅ (900, 1) ✅ (900, 2) ✅ (900, 3) ✅ (900, 4) ✅ (900, 5) ✅ (950, 1) ✅ (950, 2) ✅ (950, 3) ✅ (950, 4) ✅ (950, 5) ✅ (1000, 1) ✅ (1000, 2) ✅ (1000, 3) ✅ (1000, 4) ✅ (1000, 5) ✅ (1050, 1) ✅ (1050, 2) ✅ (1050, 3) ✅ (1050, 4) ✅ (1050, 5) ✅ (1100, 1) ✅ (1100, 2) ✅ (1100, 3) ✅ (1100, 4) ✅ (1100, 5) ✅ (1150, 1) ✅ (1150, 2) ✅ (1150, 3) ✅ (1150, 4) ✅ (1150, 5) ✅ (1200, 1) ✅ (1200, 2) ✅ (1200, 3) ✅ (1200, 4) ✅ (1200, 5) ✅ (1250, 1) ✅ (1250, 2) ✅ (1250, 3) ✅ (1250, 4) ✅ (1250, 5) ✅ (1300, 1) ✅ (1300, 2) ✅ (1300, 3) ✅ (1300, 4) ✅ (1300, 5) ✅ (1350, 1) ✅ (1350, 2) ✅ (1350, 3) ✅ (1350, 4) ✅ (1350, 5) ✅ (1400, 1) ✅ (1400, 2) ✅ (1400, 3) ✅ (1400, 4) ✅ (1400, 5) ✅ (1450, 1) ✅ (1450, 2) ✅ (1450, 3) ✅ (1450, 4) ✅ (1450, 5) ✅ (1500, 1) ✅ (1500, 2) ✅ (1500, 3) ✅ (1500, 4) ✅ (1500, 5) ✅ (1550, 1) ✅ (1550, 2) ✅ (1550, 3) ✅ (1550, 4) ✅ (1550, 5) ✅ (1600, 1) ✅ (1600, 2) ✅ (1600, 3) ✅ (1600, 4) ✅ (1600, 5) ✅ (1650, 1) ✅ (1650, 2) ✅ (1650, 3) ✅ (1650, 4) ✅ (1650, 5) ✅ (1700, 1) ✅ (1700, 2) ✅ (1700, 3) ✅ (1700, 4) ✅ (1700, 5) ✅ (1750, 1) ✅ (1750, 2) ✅ (1750, 3) ✅ (1750, 4) ✅ (1750, 5) ✅ (1800, 1) ✅ (1800, 2) ✅ (1800, 3) ✅ (1800, 4) ✅ (1800, 5) ✅ (1850, 1) ✅ (1850, 2) ✅ (1850, 3) ✅ (1850, 4) ✅ (1850, 5) ✅ (1900, 1) ✅ (1900, 2) ✅ (1900, 3) ✅ (1900, 4) ✅ (1900, 5) ✅ (1950, 1) ✅ (1950, 2) ✅ (1950, 3) ✅ (1950, 4) ✅ (1950, 5) ✅ (2000, 1) ✅ (2000, 2) ✅ (2000, 3) ✅ (2000, 4) ✅ (2000, 5) ✅ (2050, 1) ✅ (2050, 2) ✅ (2050, 3) ✅ (2050, 4) ✅ (2050, 5) ✅ (2100, 1) ✅ (2100, 2) ✅ (2100, 3) ✅ (2100, 4) ✅ (2100, 5) ✅ (2150, 1) ✅ (2150, 2) ✅ (2150, 3) ✅ (2150, 4) ✅ (2150, 5) ✅ (2200, 1) ✅ (2200, 2) ✅ (2200, 3) ✅ (2200, 4) ✅ (2200, 5) \n",
      "✔ Resultados del barrio «RUSSAFA» guardados.\n",
      "\n",
      "Procesando barrio «PATRAIX»… ✅ Supergraph PATRAIX created: 1324 nodes, 3414 edges.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PAQUETES_MIN = 1\n",
    "PAQUETES_MAX = 5\n",
    "CAPACIDAD_MAXIMA = 8\n",
    "CAPACIDAD_MAXIMA_ONA = 20\n",
    "RESULTS_PATH = '../../data/output/results_simulati.csv'\n",
    "\n",
    "# Si existe el archivo, lo borramos para empezar limpio\n",
    "if os.path.exists(RESULTS_PATH):\n",
    "    os.remove(RESULTS_PATH)\n",
    "\n",
    "# Itera sobre barrios con barra de progreso\n",
    "for nombre in tqdm(barrios['nombre'], desc='Barrios', unit=' barrio'):\n",
    "    print(f\"\\nProcesando barrio «{nombre}»…\", end=' ')\n",
    "    G_super, nodos_carga, nodos_comercios, nodos_almacenes = get_graph(nombre)\n",
    "    \n",
    "    # Lista temporal para acumular filas de este barrio\n",
    "    rows = []\n",
    "\n",
    "    for paquetes, semilla in itertools.product(range(50, int(len(nodos_comercios)*PAQUETES_MAX*0.6), 50), range(1, 6)):\n",
    "        prueba = semilla\n",
    "        for i in range(3):\n",
    "            try:\n",
    "                paq, df_comercios, nodo_entrada = generate_context(\n",
    "                    nodos_comercios,\n",
    "                    N_PAQUETES=paquetes,\n",
    "                    PAQUETES_MIN=PAQUETES_MIN,\n",
    "                    PAQUETES_MAX=PAQUETES_MAX,\n",
    "                    CAPACIDAD_MAXIMA=CAPACIDAD_MAXIMA,\n",
    "                    seed=semilla\n",
    "                )\n",
    "                \n",
    "                base = {\n",
    "                    'modelo': None,\n",
    "                    'barrio': nombre,\n",
    "                    'comercios_barrio': len(nodos_comercios),\n",
    "                    'cids_barrio': len(nodos_carga),\n",
    "                    'almacenes_barrio': len(nodos_almacenes),\n",
    "                    'paquetes': paq,\n",
    "                    'comercios_seleccionados': len(df_comercios),\n",
    "                    'semilla': prueba\n",
    "                }\n",
    "\n",
    "                m1 = simulation_M1(df_comercios, nodo_entrada, nodos_carga, CAPACIDAD_MAXIMA=CAPACIDAD_MAXIMA)\n",
    "                rows.append({**base, 'modelo': 'M1', **m1})\n",
    "\n",
    "                m2 = simulation_M2(df_comercios, nodo_entrada, nodos_almacenes, seed=prueba, CAPACIDAD_MAXIMA_ONA=CAPACIDAD_MAXIMA_ONA)\n",
    "                rows.append({**base, 'modelo': 'M2', **m2})\n",
    "\n",
    "                print(f'✅ ({paq}, {prueba})', end=' ')\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌({paquetes}, {prueba}): {e}\", end=' ')\n",
    "                prueba = random.randint(10, 1000)\n",
    "\n",
    "    # Guardar resultados del barrio actual\n",
    "    if rows:\n",
    "        df_resultados = pd.DataFrame(rows)\n",
    "        df_resultados.to_csv(RESULTS_PATH, mode='a', index=False, header=not os.path.exists(RESULTS_PATH))\n",
    "        print(f\"\\n✔ Resultados del barrio «{nombre}» guardados.\")\n",
    "    else:\n",
    "        print(f\"\\n⚠ No se pudieron generar resultados válidos para el barrio «{nombre}».\")\n",
    "\n",
    "print(\"\\n\\n🏁 Simulación completada.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
